import os
import time
import ollama
from elasticsearch import Elasticsearch
from dotenv import load_dotenv

# Load biáº¿n mÃ´i trÆ°á»ng
load_dotenv()

# Káº¿t ná»‘i Elasticsearch
ELASTICSEARCH_HOST = os.getenv("ELASTICSEARCH_HOST", "http://localhost:9200")
INDEX_NAME = "documents_toi_uu"
es = Elasticsearch(ELASTICSEARCH_HOST)

# Danh má»¥c thÆ° má»¥c theo chá»§ Ä‘á»
TOPIC_FOLDERS = {
    "Kinh táº¿": "kinh-te",
    "Khoa há»c": "khoa-hoc",
    "NhÃ¢n sá»±": "nhan-su",
}

def classify_question(question):
    """DÃ¹ng AI Ä‘á»ƒ xÃ¡c Ä‘á»‹nh chá»§ Ä‘á» cÃ¢u há»i."""
    prompt = f"""
    DÆ°á»›i Ä‘Ã¢y lÃ  danh sÃ¡ch chá»§ Ä‘á»:
    {', '.join(TOPIC_FOLDERS.keys())}

    HÃ£y phÃ¢n loáº¡i cÃ¢u há»i sau vÃ o má»™t trong cÃ¡c chá»§ Ä‘á» trÃªn:
    "{question}"

    Tráº£ lá»i chá»‰ báº±ng tÃªn chá»§ Ä‘á» chÃ­nh xÃ¡c.
    """
    response = ollama.chat(model="gemma2:9b", messages=[{"role": "user", "content": prompt}])
    topic = response["message"]["content"].strip()
    return TOPIC_FOLDERS.get(topic, None)  # Tráº£ vá» thÆ° má»¥c hoáº·c None náº¿u khÃ´ng cÃ³ káº¿t quáº£ rÃµ rÃ ng

def search_and_respond(question):
    """TÃ¬m kiáº¿m tÃ i liá»‡u trong Elasticsearch sau khi phÃ¢n loáº¡i cÃ¢u há»i."""
    start_time = time.time()
    # ğŸ§  XÃ¡c Ä‘á»‹nh thÆ° má»¥c dá»±a trÃªn AI
    folder = classify_question(question)
    if folder:
        print(f"ğŸ“‚ AI xÃ¡c Ä‘á»‹nh cÃ¢u há»i thuá»™c thÆ° má»¥c: {folder}")
        search_query = {"match": {"folder": folder}}
    else:
        print("ğŸ” AI khÃ´ng cháº¯c cháº¯n, tÃ¬m kiáº¿m trÃªn táº¥t cáº£ thÆ° má»¥c.")
        search_query = {"match_all": {}}

    # ğŸ” TÃ¬m kiáº¿m trong Elasticsearch
    search_result = es.search(index=INDEX_NAME, body={
        "query": search_query,
        "size": 3,
        "_source": ["content", "filename"]
    })

    documents = search_result["hits"]["hits"]
    
    if not documents:
        return "KhÃ´ng tÃ¬m tháº¥y tÃ i liá»‡u phÃ¹ há»£p."

    # ğŸ“„ Láº¥y ná»™i dung vÃ  nguá»“n tÃ i liá»‡u
    context = "\n\n".join([f"(ğŸ“„ {doc['_source']['filename']}) {doc['_source']['content']}" for doc in documents])
    
    prompt = f"""
    DÆ°á»›i Ä‘Ã¢y lÃ  tÃ i liá»‡u tham kháº£o:
    
    {context}

    CÃ¢u há»i: {question}

    Tráº£ lá»i má»™t cÃ¡ch chÃ­nh xÃ¡c dá»±a trÃªn tÃ i liá»‡u trÃªn.
    """

    # ğŸ¤– Gá»i AI Ä‘á»ƒ táº¡o cÃ¢u tráº£ lá»i
    response = ollama.chat(model="gemma2:9b", messages=[{"role": "user", "content": prompt}])
    
    end_time = time.time()
    print(f"â³ HoÃ n thÃ nh trong {end_time - start_time:.4f} giÃ¢y")
    return response["message"]["content"]

if __name__ == "__main__":
    while True:
        question = input("Nháº­p cÃ¢u há»i (hoáº·c 'exit' Ä‘á»ƒ thoÃ¡t): ")
        if question.lower() == "exit":
            break
        answer = search_and_respond(question)
        print("Trá»£ lÃ½ AI:", answer)
