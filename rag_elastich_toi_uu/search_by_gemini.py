import os
import time
import ollama
from elasticsearch import Elasticsearch
from dotenv import load_dotenv

# Load bi·∫øn m√¥i tr∆∞·ªùng
load_dotenv()

# K·∫øt n·ªëi Elasticsearch
ELASTICSEARCH_HOST = os.getenv("ELASTICSEARCH_HOST", "http://localhost:9200")
es = Elasticsearch(ELASTICSEARCH_HOST)

# L·∫•y danh s√°ch t·∫•t c·∫£ index c√≥ t√†i li·ªáu
try:
    all_indices = es.cat.indices(format="json")
    INDEX_NAMES = [index["index"] for index in all_indices if "index" in index and index["index"].startswith("documents_")]
except Exception as e:
    print(f"‚ö†Ô∏è L·ªói khi l·∫•y danh s√°ch index: {e}")
    INDEX_NAMES = []

# Danh m·ª•c th∆∞ m·ª•c theo ch·ªß ƒë·ªÅ
TOPIC_FOLDERS = {
    "Kinh t·∫ø": "kinh-te",
    "Khoa h·ªçc": "khoa-hoc",
    "Nh√¢n s·ª±": "nhan-su",
    "C√¥ng vi·ªác": "cong-viec-cua-toi",
}

def analyze_question(question):
    """D√πng AI ƒë·ªÉ ph√¢n t√≠ch c√¢u h·ªèi v√† x√°c ƒë·ªãnh h∆∞·ªõng x·ª≠ l√Ω."""
    prompt = f"""
    D∆∞·ªõi ƒë√¢y l√† danh s√°ch ch·ªß ƒë·ªÅ:
    {', '.join(TOPIC_FOLDERS.keys())}

    C√¢u h·ªèi: "{question}"

    H√£y ph√¢n lo·∫°i c√¢u h·ªèi v√†o m·ªôt trong c√°c tr∆∞·ªùng h·ª£p sau:
    1. Cu·ªôc h·ªôi tho·∫°i th√¥ng th∆∞·ªùng (v√≠ d·ª•: xin ch√†o, t·∫°m bi·ªát, h·ªèi thƒÉm, ...).
    2. C√¢u h·ªèi c·∫ßn t√¨m ki·∫øm d·ªØ li·ªáu c·ª• th·ªÉ trong t√†i li·ªáu (v√≠ d·ª•: ai, c√°i g√¨, ·ªü ƒë√¢u, khi n√†o, t·∫°i sao, nh∆∞ th·∫ø n√†o...).
    3. C·∫ßn t√¨m ki·∫øm theo m·ªôt trong c√°c ch·ªß ƒë·ªÅ: {', '.join(TOPIC_FOLDERS.keys())}.
    4. C·∫ßn t√¨m ki·∫øm tr√™n t·∫•t c·∫£ c√°c th∆∞ m·ª•c n·∫øu kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c ch·ªß ƒë·ªÅ c·ª• th·ªÉ.

    Tr·∫£ l·ªùi ch·ªâ b·∫±ng m·ªôt trong c√°c k·∫øt qu·∫£ sau:
    - "Cu·ªôc h·ªôi tho·∫°i"
    - "T√¨m ki·∫øm c·ª• th·ªÉ"
    - T√™n ch·ªß ƒë·ªÅ ch√≠nh x√°c (v√≠ d·ª•: "Kinh t·∫ø")
    - "T√¨m ki·∫øm t·∫•t c·∫£"
    """
    response = ollama.chat(model="gemma2:9b", messages=[{"role": "user", "content": prompt}])
    return response["message"]["content"].strip()

def search_and_respond(question):
    """T√¨m ki·∫øm t√†i li·ªáu trong Elasticsearch ho·∫∑c tr·∫£ l·ªùi tr·ª±c ti·∫øp t√πy v√†o ph√¢n t√≠ch AI."""
    start_time = time.time()
    action = analyze_question(question)

    if action == "Cu·ªôc h·ªôi tho·∫°i":
        print("üó£Ô∏è C√¢u h·ªèi l√† cu·ªôc h·ªôi tho·∫°i th√¥ng th∆∞·ªùng.")
        response = ollama.chat(model="gemma2:9b", messages=[{"role": "user", "content": question}])
        return response["message"]["content"]

    # üß† X√°c ƒë·ªãnh ki·ªÉu t√¨m ki·∫øm
    if action == "T√¨m ki·∫øm c·ª• th·ªÉ":
        print("üîç C·∫ßn t√¨m ki·∫øm d·ªØ li·ªáu c·ª• th·ªÉ trong t√†i li·ªáu.")
        search_query = {"match_all": {}}
    elif action in TOPIC_FOLDERS:
        folder = TOPIC_FOLDERS[action]
        print(f"üìÇ AI x√°c ƒë·ªãnh c√¢u h·ªèi thu·ªôc th∆∞ m·ª•c: {folder}")
        search_query = {"match": {"folder": folder}}
    else:
        print("üîç AI kh√¥ng ch·∫Øc ch·∫Øn, t√¨m ki·∫øm tr√™n t·∫•t c·∫£ th∆∞ m·ª•c.")
        search_query = {"match_all": {}}

    # üîé T√¨m ki·∫øm trong t·∫•t c·∫£ index c√≥ s·∫µn
    documents = []
    if INDEX_NAMES:
        try:
            search_result = es.search(index=",".join(INDEX_NAMES), body={
                "query": search_query,
                "size": 3,
                "_source": ["content", "filename", "folder"]
            })
            documents = search_result["hits"].get("hits", [])
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói khi t√¨m ki·∫øm: {e}")

    if not documents:
        return "Kh√¥ng t√¨m th·∫•y t√†i li·ªáu ph√π h·ª£p."

    # üìÑ Debug: In ra n·ªôi dung t√¨m ƒë∆∞·ª£c
    print(f"üîé T√¨m th·∫•y {len(documents)} t√†i li·ªáu:")
    for doc in documents:
        source = doc.get("_source", {})
        print(f"üìÑ File: {source.get('filename', 'N/A')} (Folder: {source.get('folder', 'N/A')})")
        print(f"üìú N·ªôi dung: {source.get('content', '')[:500]}...\n")

    # üìÑ L·∫•y n·ªôi dung v√† ngu·ªìn t√†i li·ªáu
    context = "\n\n".join([f"(üìÑ {doc['_source']['filename']}) {doc['_source']['content']}" for doc in documents])

    prompt = f"""
    D∆∞·ªõi ƒë√¢y l√† t√†i li·ªáu tham kh·∫£o:
    
    {context}

    C√¢u h·ªèi: {question}

    Tr·∫£ l·ªùi m·ªôt c√°ch ch√≠nh x√°c d·ª±a tr√™n t√†i li·ªáu tr√™n.
    """

    response = ollama.chat(model="gemma2:9b", messages=[{"role": "user", "content": prompt}])

    end_time = time.time()
    print(f"‚è≥ Ho√†n th√†nh trong {end_time - start_time:.4f} gi√¢y")
    return response["message"]["content"]

if __name__ == "__main__":
    while True:
        question = input("Nh·∫≠p c√¢u h·ªèi (ho·∫∑c 'exit' ƒë·ªÉ tho√°t): ")
        if question.lower() == "exit":
            break
        answer = search_and_respond(question)
        print("Tr·ª£ l√Ω AI:", answer)