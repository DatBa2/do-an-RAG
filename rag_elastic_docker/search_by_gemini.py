import os
import time
import google.generativeai as genai
from elasticsearch import Elasticsearch
from mysql_util import execute_sql_query, insert_data
from dotenv import load_dotenv

# Load bi·∫øn m√¥i tr∆∞·ªùng
load_dotenv()

# K·∫øt n·ªëi Elasticsearch
ES_HOST = os.getenv("ES_HOST", "http://localhost:9200")

es = Elasticsearch(ES_HOST)

# C·∫•u h√¨nh Gemini
genai.configure(api_key="AIzaSyCM9BL3FkNcpf0aimQCUTnGuTvhhG6zw3Q")
model = genai.GenerativeModel("gemini-2.0-flash")

# L·ªãch s·ª≠ h·ªôi tho·∫°i
history = []

# Danh m·ª•c th∆∞ m·ª•c theo ch·ªß ƒë·ªÅ
TOPIC_FOLDERS = {
    "Kinh t·∫ø": "kinh-te",
    "Khoa h·ªçc": "khoa-hoc",
    "Nh√¢n s·ª±": "nhan-su",
    "Ch∆∞a x√°c ƒë·ªãnh": "chua-xac-dinh",
    "Th√¥ng tin c√° nh√¢n": "thong-tin-ca-nhan",
}

def analyze_question(question):
    chat = model.start_chat(history=history)
    prompt = f"""
    D∆∞·ªõi ƒë√¢y l√† danh s√°ch c√°c ch·ªß ƒë·ªÅ c√≥ s·∫µn:
    {', '.join(TOPIC_FOLDERS.keys())}

    C√¢u h·ªèi: "{question}"

    H√£y ph√¢n lo·∫°i c√¢u h·ªèi v√†o m·ªôt trong c√°c lo·∫°i sau:
    1. Cu·ªôc h·ªôi tho·∫°i th√¥ng th∆∞·ªùng
    2. C√¢u h·ªèi y√™u c·∫ßu t√¨m ki·∫øm t√†i li·ªáu
    3. C√¢u h·ªèi li√™n quan ƒë·∫øn m·ªôt trong c√°c ch·ªß ƒë·ªÅ
    4. C√¢u h·ªèi c·∫ßn t√¨m ki·∫øm tr√™n t·∫•t c·∫£ c√°c th∆∞ m·ª•c

    Tr·∫£ l·ªùi ch·ªâ b·∫±ng m·ªôt trong c√°c k·∫øt qu·∫£ sau:
    - "Cu·ªôc h·ªôi tho·∫°i"
    - "T√¨m ki·∫øm c·ª• th·ªÉ"
    - T√™n ch·ªß ƒë·ªÅ ch√≠nh x√°c
    - "T√¨m ki·∫øm t·∫•t c·∫£"
    """
    response = chat.send_message(prompt)
    return response.text.strip()

def search_and_respond(question, user_id = 0, tele_id = 0):
    global history
    INDEX_NAMES = []
    try:
        all_indices = es.cat.indices(format="json")
        INDEX_NAMES = [index["index"] for index in all_indices if "index" in index and index["index"].startswith("documents_")]
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói khi l·∫•y danh s√°ch index: {e}")
        INDEX_NAMES = []

    start_time = time.time()
    action = analyze_question(question)

    if action == "Cu·ªôc h·ªôi tho·∫°i":
        print("üó£Ô∏è C√¢u h·ªèi l√† cu·ªôc h·ªôi tho·∫°i th√¥ng th∆∞·ªùng.")
        chat = model.start_chat(history=history)
        response = chat.send_message(question)
        history.append({"role": "user", "parts": [question]})
        history.append({"role": "model", "parts": [response.text]})
        end_time = time.time()
        print(f"‚è≥ Ho√†n th√†nh trong {end_time - start_time:.4f} gi√¢y")
        save_chat_history(user_id, tele_id, question, response.text)
        return response.text

    selected_indices = INDEX_NAMES
    search_query = {}

    if action == "T√¨m ki·∫øm c·ª• th·ªÉ":
        print("üîç C·∫ßn t√¨m ki·∫øm d·ªØ li·ªáu c·ª• th·ªÉ trong t√†i li·ªáu.")
        search_query = {
            "bool": {
                "must": [
                    {
                        "multi_match": {
                            "query": question,
                            "fields": ["content_clean^2", "content"],
                            "type": "most_fields"
                        }
                    }
                ]
            }
        }
    elif action in TOPIC_FOLDERS:
        folder = TOPIC_FOLDERS[action]
        print(f"üìÇ AI x√°c ƒë·ªãnh c√¢u h·ªèi thu·ªôc th∆∞ m·ª•c: {folder}")
        selected_indices = []
        main_index = f"documents_{folder}"
        backup_index = "documents_chua-xac-dinh"

        if main_index in INDEX_NAMES:
            selected_indices.append(main_index)
        if backup_index in INDEX_NAMES:
            selected_indices.append(backup_index)

        if not selected_indices:
            print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y index ph√π h·ª£p.")
            return "Kh√¥ng t√¨m th·∫•y t√†i li·ªáu ph√π h·ª£p."

        search_query = {
            "bool": {
                "must": [{"match": {"content_clean": question}}],
                "should": [
                    {"match": {"folder": folder}},
                    {"match": {"folder": "chua-xac-dinh"}},
                ]
            }
        }
    else:
        print("üîç AI kh√¥ng ch·∫Øc ch·∫Øn, t√¨m ki·∫øm tr√™n t·∫•t c·∫£ th∆∞ m·ª•c.")
        search_query = {
            "bool": {
                "must": [{"match": {"content_clean": question}}],
                "should": [{"match_phrase": {"content": question}}]
            }
        }

    documents = []
    if selected_indices:
        try:
            size_limit = 5
            search_result = es.search(index=",".join(selected_indices), body={
                "query": search_query,
                "_source": ["content", "filename", "folder", "file_path"],
                "from": 0, 
                "size": size_limit,
                "track_total_hits": False,
                "highlight": {
                    "fields": {"content": {"fragment_size": 500, "number_of_fragments": 5}}
                }
            }, request_cache=True)
            documents = search_result["hits"].get("hits", [])
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói khi t√¨m ki·∫øm: {e}")

    if not documents:
        return "Kh√¥ng t√¨m th·∫•y t√†i li·ªáu ph√π h·ª£p."

    context = " ".join([
        f"(üìÑ {doc['_source']['filename']} - {doc['_source']['folder']})\n"
        f"ƒê∆∞·ªùng d·∫´n: {doc['_source'].get('file_path', 'Kh√¥ng r√µ')}\n"
        f"{' '.join(doc.get('highlight', {}).get('content', []) or [doc['_source']['content'][:500]])}"
        for doc in documents
    ])
    print(context)
    prompt = f"""
    D∆∞·ªõi ƒë√¢y l√† t√†i li·ªáu tham kh·∫£o:
    {context}
    C√¢u h·ªèi: {question}
    Tr·∫£ l·ªùi d·ª±a v√†o t√†i li·ªáu tham kh·∫£o tr√™n. N·∫øu kh√¥ng c√≥ d·ªØ li·ªáu ph√π h·ª£p hay b·ªè qua kh√¥ng c·∫ßn tr√¨nh b√†y h√£y tr·∫£ l·ªùi b·∫±ng v·ªën hi·ªÉu bi·∫øt c·ªßa b·∫°n
    """
    history.append({"role": "user", "parts": [f"[T√†i li·ªáu tham kh·∫£o]\n{context}\n\nC√¢u h·ªèi: {question}"]})

    chat = model.start_chat(history=history)
    response = chat.send_message(prompt)

    history.append({"role": "model", "parts": [response.text]})

    end_time = time.time()
    print(f"‚è≥ Ho√†n th√†nh trong {end_time - start_time:.4f} gi√¢y")
    save_chat_history(user_id, tele_id, question, response.text)
    return response.text


def save_chat_history(user_id: int, tele_id: int, message: str, response: str):
    query = "INSERT INTO chat_history (user_id, tele_id, message, response) VALUES (%s, %s, %s, %s)"
    params = (user_id, tele_id, message, response)
    insert_data(query, params)

history_chat = []
def chat_and_respond(question, user_id = 0, tele_id = 0):
    global history_chat
    start_time = time.time()
    chat = model.start_chat(history=history_chat)
    response = chat.send_message(question)
    history_chat.append({"role": "user", "parts": [question]})
    history_chat.append({"role": "model", "parts": [response.text]})
    end_time = time.time()
    print(f"‚è≥ Ho√†n th√†nh trong {end_time - start_time:.4f} gi√¢y")
    save_chat_history(user_id, tele_id, question, response.text)
    return response.text

if __name__ == "__main__":
    while True:
        question = input("Nh·∫≠p c√¢u h·ªèi (ho·∫∑c 'exit' ƒë·ªÉ tho√°t): ")
        if question.lower() in ["exit", "quit", "tho√°t"]:
            print("K·∫øt th√∫c h·ªôi tho·∫°i.")
            break
        answer = search_and_respond(question)
        print("Tr·ª£ l√Ω AI:", answer)
