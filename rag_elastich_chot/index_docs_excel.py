import os
import time
import hashlib
import pandas as pd
from elasticsearch import Elasticsearch, helpers
from dotenv import load_dotenv
from tqdm import tqdm

# Load biáº¿n mÃ´i trÆ°á»ng
load_dotenv()

# Káº¿t ná»‘i Elasticsearch
ELASTICSEARCH_HOST = os.getenv("ELASTICSEARCH_HOST", "http://localhost:9200")
es = Elasticsearch(ELASTICSEARCH_HOST)

# ğŸ“š Äá»c dá»¯ liá»‡u tá»« nhiá»u thÆ° má»¥c con
BASE_FOLDER = "txt"  # ğŸ“Œ ThÆ° má»¥c gá»‘c chá»©a cÃ¡c thÆ° má»¥c con

documents = []
start_time = time.time()  # â³ Báº¯t Ä‘áº§u Ä‘o thá»i gian

def hash_content(content):
    """Táº¡o hash SHA256 cho ná»™i dung file Ä‘á»ƒ kiá»ƒm tra thay Ä‘á»•i."""
    return hashlib.sha256(content.encode("utf-8")).hexdigest()

# ğŸ› ï¸ Táº¡o index náº¿u chÆ°a cÃ³
def create_index_if_not_exists(index_name):
    if not es.indices.exists(index=index_name):
        es.indices.create(index=index_name, body={
            "settings": {
                "number_of_shards": 3,  # ğŸ”¹ Chia dá»¯ liá»‡u ra 3 pháº§n Ä‘á»ƒ tÄƒng tá»‘c truy váº¥n
                "number_of_replicas": 1  # ğŸ”¹ Má»—i shard cÃ³ 1 báº£n sao Ä‘á»ƒ tÄƒng Ä‘á»™ tin cáº­y
            },
            "mappings": {
                "properties": {
                    "content": {"type": "text"},
                    "filename": {"type": "keyword"},
                    "folder": {"type": "keyword"},
                    "content_hash": {"type": "keyword"}  # ğŸ” DÃ¹ng Ä‘á»ƒ kiá»ƒm tra trÃ¹ng láº·p
                }
            }
        })

for root, _, files in os.walk(BASE_FOLDER):
    folder_name = os.path.basename(root)  # Láº¥y tÃªn thÆ° má»¥c con
    index_name = f"documents_{folder_name.lower()}"  # Táº¡o index theo tÃªn thÆ° má»¥c
    create_index_if_not_exists(index_name)  # Táº¡o index náº¿u chÆ°a cÃ³

    batch_documents = []  # LÆ°u batch dá»¯ liá»‡u Ä‘á»ƒ bulk update

    for file_name in tqdm(files, desc=f"ğŸ“‚ Äang xá»­ lÃ½ ({folder_name})"):
        file_path = os.path.join(root, file_name)
        content = ""

        try:
            # Xá»­ lÃ½ file .txt
            if file_name.endswith(".txt"):
                with open(file_path, "r", encoding="utf-8") as f:
                    content = f.read()

            # Xá»­ lÃ½ file .xlsx vÃ  .xls
            elif file_name.endswith(".xlsx"):
                df = pd.read_excel(file_path, sheet_name=None, engine="openpyxl")
                content = "\n".join([df[sheet].to_string(index=False) for sheet in df])
            elif file_name.endswith(".xls"):
                try:
                    df = pd.read_excel(file_path, sheet_name=None, engine="xlrd")
                    content = "\n".join([df[sheet].to_string(index=False) for sheet in df])
                except Exception as xlrd_error:
                    print(f"âš ï¸ Lá»—i xlrd vá»›i file {file_name}, thá»­ openpyxl: {xlrd_error}")
                    try:
                        df = pd.read_excel(file_path, sheet_name=None, engine="openpyxl")
                        content = "\n".join([df[sheet].to_string(index=False) for sheet in df])
                    except Exception as openpyxl_error:
                        print(f"âŒ KhÃ´ng thá»ƒ Ä‘á»c file {file_name}: {openpyxl_error}")
                        continue
        except Exception as e:
            print(f"âš ï¸ Lá»—i Ä‘á»c file {file_name}: {e}")
            continue

        if not content:
            continue

        # ğŸ” Táº¡o hash ná»™i dung lÃ m ID
        content_hash = hash_content(content)
        doc_id = hashlib.sha1(content.encode("utf-8")).hexdigest()

        # âœ… Gom dá»¯ liá»‡u vÃ o batch Ä‘á»ƒ bulk update
        batch_documents.append({
            "_op_type": "index",
            "_index": index_name,
            "_id": doc_id,  # DÃ¹ng hash lÃ m ID Ä‘á»ƒ kiá»ƒm tra trÃ¹ng láº·p
            "_source": {
                "content": content,
                "filename": file_name,
                "folder": folder_name,
                "content_hash": content_hash
            }
        })

    # ğŸš€ Bulk index toÃ n bá»™ batch
    if batch_documents:
        helpers.bulk(es, batch_documents)
        print(f"âœ… ÄÃ£ index {len(batch_documents)} tÃ i liá»‡u má»›i trong {folder_name}.")

end_time = time.time()
print(f"ğŸš€ HoÃ n táº¥t náº¡p dá»¯ liá»‡u! â³ Tá»•ng thá»i gian: {end_time - start_time:.2f} giÃ¢y")
